{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running L-BFGS-B (Scipy implementation) Code:\n",
      "  runtime   i      f              |g|        \n",
      "    00s11  0001   7.775773e+01   3.319627e+00 \n",
      "    01s22  0013   7.697339e+01   2.944368e-11 \n",
      "Runtime:     01s22\n",
      "Optimization status: Converged\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import GPy\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "X_train = np.random.uniform(-3.,3.,(50,1)) # Training inputs\n",
    "Y_train = np.sin(X_train) + np.random.randn(50,1)*0.05 # Training outputs\n",
    "\n",
    "# Example of base models' predictions for ensemble (simulated here as random)\n",
    "f_k = np.random.randn(50, 1)\n",
    "\n",
    "\n",
    "# Define the zero mean function for the GP\n",
    "mean_function = GPy.mappings.Constant(input_dim=1, output_dim=1, value=0)\n",
    "\n",
    "# Define the kernel function with Radial Basis Function (RBF)\n",
    "# The variance and lengthscale are hyperparameters and should be chosen according to the problem at hand.\n",
    "kernel = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "\n",
    "# Create the Gaussian Process model\n",
    "gp_model = GPy.models.GPRegression(X_train, Y_train - f_k, kernel, mean_function=mean_function)\n",
    "\n",
    "# Fit the GP model to the residuals\n",
    "gp_model.optimize(messages=True)\n",
    "\n",
    "# Predict using the GP model to get the residual process\n",
    "X_test = np.linspace(-5, 5, 100).reshape(-1, 1)  # Test inputs\n",
    "mean, variance = gp_model.predict(X_test)  # Residual process predictions\n",
    "\n",
    "# Final prediction considering the ensemble and the residual process\n",
    "ensemble_prediction = f_k.mean() + mean  # Assuming f_k.mean() as a dummy ensemble prediction\n",
    "\n",
    "# The complete model prediction would be the sum of the ensemble predictions and the GP residuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPy\n",
      "  Using cached GPy-1.13.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy>=1.7 in /Users/kaylahuang/opt/anaconda3/envs/pymc_env/lib/python3.11/site-packages (from GPy) (1.26.4)\n",
      "Requirement already satisfied: six in /Users/kaylahuang/opt/anaconda3/envs/pymc_env/lib/python3.11/site-packages (from GPy) (1.16.0)\n",
      "Collecting paramz>=0.9.6 (from GPy)\n",
      "  Using cached paramz-0.9.6-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting cython>=0.29 (from GPy)\n",
      "  Using cached Cython-3.0.10-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting scipy<1.12.0,>=1.3.0 (from GPy)\n",
      "  Using cached scipy-1.11.4-cp311-cp311-macosx_12_0_arm64.whl.metadata (165 kB)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /Users/kaylahuang/opt/anaconda3/envs/pymc_env/lib/python3.11/site-packages (from paramz>=0.9.6->GPy) (5.1.1)\n",
      "Using cached GPy-1.13.1-cp311-cp311-macosx_10_9_universal2.whl (1.9 MB)\n",
      "Using cached Cython-3.0.10-py2.py3-none-any.whl (1.2 MB)\n",
      "Using cached paramz-0.9.6-py3-none-any.whl (103 kB)\n",
      "Using cached scipy-1.11.4-cp311-cp311-macosx_12_0_arm64.whl (29.7 MB)\n",
      "Installing collected packages: scipy, cython, paramz, GPy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.13.0\n",
      "    Uninstalling scipy-1.13.0:\n",
      "      Successfully uninstalled scipy-1.13.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pymc 5.13.1 requires pytensor<2.21,>=2.20, but you have pytensor 2.13.1 which is incompatible.\n",
      "arviz 0.18.0 requires pandas>=1.5.0, but you have pandas 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed GPy-1.13.1 cython-3.0.10 paramz-0.9.6 scipy-1.11.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration function\n",
    "import GPy\n",
    "import numpy as np\n",
    "\n",
    "# Simulated observed data\n",
    "X_observed = np.random.uniform(-3., 3., (50, 1))  # Observed input locations\n",
    "Y_observed = np.random.uniform(0, 1, (50, 1))  # Observed CDF values (should be between 0 and 1)\n",
    "\n",
    "# Define the kernel function - Mat√©rn 3/2 kernel\n",
    "kernel_G = GPy.kern.Matern32(input_dim=1, variance=1., lengthscale=1.)\n",
    "\n",
    "# Since we want G to be a CDF, the mean function should be identity, but GPy does not have this functionality out of the box.\n",
    "# So we use a zero mean function, and we will need to enforce monotonicity through other means, such as post-processing or constraints during optimization.\n",
    "mean_function_G = GPy.mappings.Linear(input_dim=1, output_dim=1)\n",
    "mean_function_G.C = np.array([[1]])  # Identity mapping\n",
    "mean_function_G.bias = np.array([[0]])  # No bias\n",
    "\n",
    "# Create the Gaussian Process model for G\n",
    "gp_calibration = GPy.models.GPRegression(X_observed, Y_observed, kernel_G, mean_function=mean_function_G)\n",
    "\n",
    "# Optimization constraints would be added here to ensure the output is monotonically increasing and bounded between 0 and 1.\n",
    "\n",
    "# Fit the GP model to the observed CDF data\n",
    "gp_calibration.optimize(messages=True)\n",
    "\n",
    "# Example use: Calibrating a new set of predictions\n",
    "X_new = np.linspace(-5, 5, 100).reshape(-1, 1)  # New input locations\n",
    "Phi_e_new = np.random.uniform(0, 1, (100, 1))  # New predictions for CDF values from the base ensemble model\n",
    "\n",
    "# Use the GP model to calibrate the new predictions\n",
    "G_Phi_e_new, _ = gp_calibration.predict(X_new)\n",
    "\n",
    "# The calibrated predictions would then be G(Phi_e_new), which you'd get by passing Phi_e_new through the calibration model G.\n",
    "# Since our GP model does not directly apply to this form, one would need to adjust the predictions manually or alter the GP setup to support this functionality.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat195",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
